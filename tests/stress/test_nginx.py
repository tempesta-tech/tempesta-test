"""
HTTP Stress tests with NGINX in place of Tempesta FW - to compare results.
"""

from framework.helpers import dmesg
from framework.helpers.cert_generator_x509 import CertGenerator
from framework.helpers.tf_cfg import cfg
from framework.test_suite import marks, tester
from tests.stress.test_stress import BaseCurlStress, LargePageNginxBackendMixin

__author__ = "Tempesta Technologies, Inc."
__copyright__ = "Copyright (C) 2022 Tempesta Technologies, Inc."
__license__ = "GPL2"


# Config to start Nginx instead of Tempesta on 80 and 443 ports
NGINX_PROXY_CONFIG = """
pid ${pid};
worker_processes  auto;
events {
    worker_connections   1024;
    use epoll;
}
http {
    keepalive_timeout ${server_keepalive_timeout};
    keepalive_requests ${server_keepalive_requests};
    sendfile         on;
    tcp_nopush       on;
    tcp_nodelay      on;
    open_file_cache max=1000;
    open_file_cache_valid 30s;
    open_file_cache_min_uses 2;
    open_file_cache_errors off;
    error_log /dev/null emerg;
    access_log off;
    server {
        listen 80;
        listen 443 ssl http2;
        server_name tempesta-tech.com;
        ssl_certificate ${server_workdir}/nginx_proxy.crt;
        ssl_certificate_key ${server_workdir}/nginx_proxy.key;
        ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
        ssl_ciphers HIGH:!aNULL:!MD5;
        location / {
            proxy_pass http://${server_ip}:8000;
        }
        location /nginx_status {
            stub_status on;
        }
    }
}
"""


class NginxProxyMixin:
    """
    Mixin to run Nginx instead of Tempesta in tests,
    to compare the result with Tempesta under the same circumstances.
    """

    def setUp(self):
        self.backends = [
            *self.backends[:],
            {
                "id": "nginx_proxy",
                "type": "nginx",
                "port": "80",
                "status_uri": "http://${server_ip}:80/nginx_status",
                "config": NGINX_PROXY_CONFIG,
            },
        ]
        super().setUp()

    def start_all(self):
        # Start servers, but not Tempesta
        self.create_cert()
        self.start_all_servers()
        self.deproxy_manager.start()

    def create_cert(self):
        server = self.get_server("nginx_proxy")
        workdir = cfg.get("Server", "workdir")
        cert_path = f"{workdir}/nginx_proxy.crt"
        key_path = f"{workdir}/nginx_proxy.key"

        cgen = CertGenerator(cert_path, key_path, default=True)
        server.node.copy_file(cert_path, cgen.serialize_cert().decode())
        server.node.copy_file(key_path, cgen.serialize_priv_key().decode())


class NginxStressBase(NginxProxyMixin, tester.TempestaTest, base=True):
    @marks.set_stress_mtu
    @dmesg.limited_rate_on_tempesta_node
    def test(self):
        # Start servers, but not Tempesta
        self.start_all()
        wrk = self.get_client("wrk")
        wrk.set_script("foo", content='wrk.method="GET"')
        wrk.timeout = 0

        wrk.start()
        self.wait_while_busy(wrk, timeout=20)
        wrk.stop()

        self.assertGreater(wrk.statuses[200], 0)


class NginxWrkStress(LargePageNginxBackendMixin, NginxStressBase):
    """Nginx HTTP stress test generated by `wrk` with concurrent connections."""

    clients = [
        {
            "id": "wrk",
            "type": "wrk",
            "addr": "${tempesta_ip}:80/1",
        },
    ]


class NginxTlsWrkStress(LargePageNginxBackendMixin, NginxStressBase):
    """Nginx HTTPS stress test generated by `wrk` with concurrent connections."""

    clients = [
        {
            "id": "wrk",
            "type": "wrk",
            "ssl": True,
            "addr": "${tempesta_ip}:443",
        },
    ]


class NginxCurlStress(NginxProxyMixin, BaseCurlStress):
    """Nginx HTTP stress test generated by `curl`."""

    proto = "http"


class NginxTlsCurlStress(NginxProxyMixin, BaseCurlStress):
    """Nginx HTTPS stress test generated by `curl`."""

    proto = "https"

    def setUp(self):
        self.clients = [{**client, "ssl": True} for client in self.clients]
        super().setUp()


class NginxH2CurlStress(NginxProxyMixin, BaseCurlStress):
    """Nginx HTTP/2 stress test generated by `curl`."""

    proto = "h2"

    def setUp(self):
        self.clients = [{**client, "http2": True} for client in self.clients]
        super().setUp()
